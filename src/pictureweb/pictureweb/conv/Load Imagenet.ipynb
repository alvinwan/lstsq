{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['imread']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import imagenet_load\n",
    "from importlib import reload\n",
    "reload(imagenet_load)\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import imread\n",
    "%pylab inline\n",
    "import imread\n",
    "from imread import imread_from_blob\n",
    "from imagenet_load import orient\n",
    "import multigpu\n",
    "reload(multigpu)\n",
    "import filter_gen\n",
    "import conv\n",
    "reload(conv)\n",
    "import gc\n",
    "import logging\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There exists a matrix at /dev/shm/imagenet_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 ms, sys: 360 ms, total: 408 ms\n",
      "Wall time: 613 ms\n"
     ]
    }
   ],
   "source": [
    "%time loader = imagenet_load.ImagenetLoader(10, classes_path=\"../classes\", mmap_loc=\"/dev/shm/imagenet_train\", n_procs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 classes into mem\n",
      "CPU times: user 48 ms, sys: 108 ms, total: 156 ms\n",
      "Wall time: 3.27 s\n"
     ]
    }
   ],
   "source": [
    "%time X = loader.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fg = filter_gen.make_gaussian_filter_gen(1.0, patch_size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_mmap(*args,\n",
    "         **kwargs):\n",
    "         from importlib import reload\n",
    "         import conv\n",
    "         import multigpu\n",
    "         reload(conv)\n",
    "         reload(multigpu)\n",
    "         sidx = kwargs[\"sidx\"]\n",
    "         eidx = kwargs[\"eidx\"]\n",
    "         mmap_in_loc = kwargs[\"mmap_in_loc\"]\n",
    "         mmap_in_shape = kwargs[\"mmap_in_shape\"]\n",
    "         X = np.memmap(mmap_in_loc, mode=\"r\", dtype='uint8', shape=mmap_in_shape)\n",
    "         mmap_out_shape = conv.conv_compute_output_shape(data=X, **kwargs)\n",
    "         X = X[sidx:eidx,:,:,:]\n",
    "         mmap_out_loc = kwargs[\"mmap_out_loc\"]   \n",
    "         X_out = np.memmap(mmap_out_loc, mode=\"r+\", dtype='float32', shape=mmap_out_shape)[sidx:eidx,:,:,:]\n",
    "         X_out_local, filters = conv._conv(X,\n",
    "                      filter_gen=kwargs[\"filter_gen\"],                                                                                                                                                                         \n",
    "                      num_feature_batches=kwargs[\"num_feature_batches\"],                                    \n",
    "                      feature_batch_size=kwargs[\"feature_batch_size\"],\n",
    "                      data_batch_size=kwargs[\"data_batch_size\"],\n",
    "                      pool_type=kwargs[\"pool_type\"],\n",
    "                      pool_size=kwargs[\"pool_size\"],\n",
    "                      pool_stride=kwargs[\"pool_stride\"],\n",
    "                      pad=kwargs[\"pad\"],\n",
    "                      bias=kwargs[\"bias\"],\n",
    "                      patch_size=kwargs[\"patch_size\"],\n",
    "                      conv_stride=kwargs[\"conv_stride\"])\n",
    "         np.copyto(X_out, X_out_local)\n",
    "         X_out.flush()\n",
    "         return multigpu.MmapResult(mmap_out_loc, 'float32', mmap_out_shape, \"r+\", range(sidx,eidx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5105)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "gpu = multigpu.GpuHandler(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_args = \\\n",
    "{ \n",
    "  \"sidx\":0,\n",
    "  \"eidx\":4096,\n",
    "  \"mmap_in_loc\":\"/dev/shm/imagenet_train\",\n",
    "  \"mmap_in_shape\":X.shape,\n",
    "  \"mmap_out_loc\": \"/dev/shm/xout\",\n",
    "  \"filter_gen\":fg,\n",
    "  \"num_feature_batches\":2,\n",
    "  \"data_batch_size\":128,\n",
    "  \"feature_batch_size\":256,\n",
    "  \"pool_size\":32,\n",
    "  \"pool_type\":\"avg\",\n",
    "  \"pool_stride\":32,\n",
    "  \"patch_size\":11,\n",
    "  \"pad\":0,\n",
    "  \"bias\":1,\n",
    "  \"conv_stride\":4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mmap_out_shape = conv.conv_compute_output_shape(data=X, **conv_args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
